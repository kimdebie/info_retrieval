{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework part B: implementing a sample size estimator for interleaving experiments\n",
    "\n",
    "#### by Kim de Bie, Bram van den Heuvel and Kiki van Rongen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Simulate Rankings of Relevance for E and P\n",
    "\n",
    "In the first step generate pairs of rankings, for the production P and experimental E, respectively. Assume a binary relevance. Make no assumption regarding the documents returned by the two algorithms (they can be distinct but they may also overlap). Further, assume that the algorithms are used on mobiles, so we are interested only in rankings of length 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.16666666666666666: 26, 0.5: 17, 0.25: 17, 0.3333333333333333: 17, 0.125: 13, 0.375: 13, 0.08333333333333337: 13, 0.41666666666666674: 13, 0.08333333333333331: 13, 0.08333333333333326: 13, 0.33333333333333337: 5, 0.08333333333333334: 4, 0.625: 4, 0.2916666666666667: 4, 0.5833333333333334: 4, 0.25000000000000006: 4, 0.16666666666666663: 4, 0.41666666666666663: 4, 0.16666666666666669: 1, 0.45833333333333337: 1, 0.6666666666666666: 1})\n"
     ]
    }
   ],
   "source": [
    "class Ranking:\n",
    "\n",
    "    def __init__(self, id, ranker):\n",
    "        self.id = id\n",
    "        self.ERR = 0\n",
    "        self.ranker = ranker\n",
    "        self.ranking = [{'id': 1, 'relevance': 0}, {'id': 2, 'relevance': 0}, {'id': 3, 'relevance': 0}]\n",
    "\n",
    "    def set_ERR(self):\n",
    "        self.ERR = self.calculate_ERR()\n",
    "        \n",
    "    def calculate_ERR(self):\n",
    "\n",
    "        max_rl = 1\n",
    "\n",
    "        thetas = []\n",
    "        for idx, docu in enumerate(self.ranking):\n",
    "            rl = docu['relevance']\n",
    "            thetas.append((2**rl - 1) / (2**max_rl))\n",
    "            \n",
    "\n",
    "        # calculate ERR as sum of products\n",
    "        ERR = 0\n",
    "        for rank, doc in enumerate(self.ranking):\n",
    "            prod = 1\n",
    "            for i in range(rank):\n",
    "                prod *= (1-thetas[i])\n",
    "            ERR+= (prod * thetas[rank])/ (rank+1)\n",
    "            \n",
    "        return ERR\n",
    "    \n",
    "\n",
    "class Pair:\n",
    "    \n",
    "    def __init__(self, ranking_E, ranking_P):\n",
    "        self.rankings = [ranking_E, ranking_P]\n",
    "        self.delta_ERR = ranking_E.ERR - ranking_P.ERR\n",
    "\n",
    "\n",
    "def create_pairs():\n",
    "\n",
    "    \"\"\"\n",
    "    This function creates two ranked lists of documents for algorithm P and E.\n",
    "    Subsequently, it forms E-P pairs of possible rankings.\n",
    "    \"\"\"\n",
    "\n",
    "    ############### CREATE RANKED LIST FOR E ###############\n",
    "\n",
    "    rankings_E = []\n",
    "    rankings_P = []\n",
    "\n",
    "    # define all possible combinations of relevance labels\n",
    "    rl_permutations = [[0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 0, 1], [0, 1, 1], [1, 1, 1]]\n",
    "\n",
    "    # assign id to the rankings\n",
    "    id = 0\n",
    "\n",
    "    # iterate over permutations of relevance labels\n",
    "    for rl_perm in rl_permutations:\n",
    "\n",
    "        # create ranking object and adjust its relevance labels\n",
    "        rank_E = Ranking(id, 'E')\n",
    "        for i, document_E in enumerate(rank_E.ranking):\n",
    "             document_E['relevance'] = rl_perm[i]\n",
    "\n",
    "        # calculate ERR\n",
    "        rank_E.set_ERR()\n",
    "\n",
    "        # store ranking list for E\n",
    "        rankings_E.append(rank_E)\n",
    "        id += 1\n",
    "\n",
    "    ############### CREATE RANKED LIST FOR P ###############\n",
    "\n",
    "    # define all possible id's for P\n",
    "    id_permutations = [[1, 5, 6], [2, 5, 6], [3, 5, 6], [4, 5, 6], \\\n",
    "                       [4, 1, 6], [4, 2, 6], [4, 3, 6], \\\n",
    "                       [4, 5, 1], [4, 5, 2], [4, 5, 3], \\\n",
    "                       [1, 2, 6], [1, 5, 2], [4, 1, 2], \\\n",
    "                       [1, 3, 6], [1, 5, 3], [4, 1, 3], \\\n",
    "                       [2, 3, 6], [2, 5, 3], [4, 2, 3], \\\n",
    "                       [2, 1, 6], [2, 5, 1], [4, 2, 1], \\\n",
    "                       [3, 1, 6], [3, 5, 1], [4, 3, 1], \\\n",
    "                       [3, 2, 6], [3, 5, 2], [4, 3, 2], \\\n",
    "                       [1, 2, 3], [1, 3, 2], [3, 1, 2], [3, 2, 1], [2, 1, 3], [2, 3, 1]]\n",
    "\n",
    "    # iterate over possible id's for P\n",
    "    for id_perm in id_permutations:\n",
    "\n",
    "        # iterate over permutations of relevance labels\n",
    "        for rl_perm in rl_permutations:\n",
    "\n",
    "            # create ranking object for P\n",
    "            rank_P = Ranking(id, 'P')\n",
    "\n",
    "            # adjust relevance labels & id numbers\n",
    "            for j, document_P in enumerate(rank_P.ranking):\n",
    "                document_P['relevance'] = rl_perm[j]\n",
    "                document_P['id'] = id_perm[j]\n",
    "\n",
    "            # calculate ERR\n",
    "            rank_P.set_ERR()\n",
    "\n",
    "            # store ranking list for P\n",
    "            rankings_P.append(rank_P)\n",
    "            id += 1\n",
    "\n",
    "    ############### FORM E-P PAIRS ###############\n",
    "\n",
    "    pairs = []\n",
    "\n",
    "    for rank_E in rankings_E:\n",
    "\n",
    "        # store ids and relevance labels of E\n",
    "        ids_E = [1, 2, 3]\n",
    "        rl_E = [d.get('relevance') for d in rank_E.ranking]\n",
    "\n",
    "        for rank_P in rankings_P:\n",
    "\n",
    "            # keep track of errors (duplicates with non-matching rl's)\n",
    "            error = False\n",
    "\n",
    "            # store ids and relevance labels of P\n",
    "            ids_P = [d.get('id') for d in rank_P.ranking]\n",
    "            rl_P = [d.get('relevance') for d in rank_P.ranking]\n",
    "\n",
    "            # iterate over ids of P\n",
    "            for idx, id in enumerate(ids_P):\n",
    "\n",
    "                # check for duplicates with non-matching relevance labels\n",
    "                if (id in ids_E) & (rl_P[idx] != rl_E[idx]):\n",
    "                    error = True\n",
    "                    break\n",
    "\n",
    "            # create pair and add to list, if no error occurs\n",
    "            if not error:\n",
    "                pair = Pair(rank_E, rank_P)\n",
    "                if 0.05 < pair.delta_ERR < 0.95:\n",
    "                    pairs.append(pair)\n",
    "\n",
    "    return pairs\n",
    "\n",
    "pairs = create_pairs()\n",
    "counter = Counter()\n",
    "for i, p in enumerate(pairs):\n",
    "    counter[p.delta_ERR] += 1\n",
    "        \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Calculate the 𝛥ERR\n",
    "Implement the aforementioned measure, ERR.\n",
    "\n",
    "For all P and E ranking pairs constructed above calculate the difference: 𝛥measure = measureE-measureP. Consider only those pairs for which E outperforms P and group them such that group 1 contains all pairs for which 0.05 < 𝛥measure ≤ 0.1, group 2 all pairs for which 0.1 < 𝛥measure ≤ 0.2, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See previous step for loading pairs and calculation of (delta-)ERR.\n",
    "\n",
    "def create_groups(pairs):\n",
    "    \"\"\"\n",
    "    This function seperates pairs into groups based on delta_ERR intervals.\n",
    "    It returns a list of sublists; each sublists contains an object of class Pair\n",
    "    \"\"\"\n",
    "\n",
    "    group1 = [p for p in pairs if (p.delta_ERR>=0.05 and p.delta_ERR<0.1)]\n",
    "    group2 = [p for p in pairs if (p.delta_ERR>=0.1 and p.delta_ERR<0.2)]\n",
    "    group3 = [p for p in pairs if (p.delta_ERR>=0.2 and p.delta_ERR<0.3)]\n",
    "    group4 = [p for p in pairs if (p.delta_ERR>=0.3 and p.delta_ERR<0.4)]\n",
    "    group5 = [p for p in pairs if (p.delta_ERR>=0.4 and p.delta_ERR<0.5)]\n",
    "    group6 = [p for p in pairs if (p.delta_ERR>=0.5 and p.delta_ERR<0.6)]\n",
    "    group7 = [p for p in pairs if (p.delta_ERR>=0.6 and p.delta_ERR<0.7)]\n",
    "    group8 = [p for p in pairs if (p.delta_ERR>=0.7 and p.delta_ERR<0.8)]\n",
    "    group9 = [p for p in pairs if (p.delta_ERR>=0.8 and p.delta_ERR<0.9)]\n",
    "    group10 = [p for p in pairs if (p.delta_ERR>=0.9 and p.delta_ERR<=0.95)]\n",
    "\n",
    "    data = [group1, group2, group3, group4, group5, group6, group7, \\\n",
    "            group8, group9, group10]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Team-Draft Interleaving and Probabilistic Interleaving\n",
    "\n",
    "Implement Team-Draft and Probabilistic Interleaving, with methods that interleave two rankings, and given the users clicks on the interleaved ranking assign credit to the algorithms that produced the rankings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interleaved:\n",
    "    def __init__(self, pair):\n",
    "        \"\"\"\n",
    "        blablabla\n",
    "        \"\"\"\n",
    "        self.pair = pair\n",
    "        self.list = None\n",
    "\n",
    "    def team_draft(self):\n",
    "        \"\"\"\n",
    "        Takes the rankings in pair and merges them using team draft\n",
    "        interleaving. The interleaved list contains tuples of form\n",
    "        (relevance, ranker).\n",
    "        \"\"\"\n",
    "        interleaved_list = []\n",
    "        available_E = set([i[\"id\"] for i in self.pair.rankings[0].ranking])\n",
    "        available_P = set([i[\"id\"] for i in self.pair.rankings[1].ranking])\n",
    "        available = available_E.union(available_P)\n",
    "        team = [0,0]\n",
    "\n",
    "        while len(available_E.intersection(available)) > 0 \\\n",
    "                and len(available_P.intersection(available)) > 0:\n",
    "\n",
    "            # Flip a coin to determine which ranker is first\n",
    "            ranker = int(team[0] > team[1] or (team[0] == team[1]\n",
    "                         and random.choice([0,1]) == 1))\n",
    "\n",
    "            for document in self.pair.rankings[ranker].ranking:\n",
    "                if document[\"id\"] in available:\n",
    "                    interleaved_list.append((document[\"relevance\"], ranker))\n",
    "                    available.remove(document[\"id\"])\n",
    "                    team[ranker] += 1\n",
    "                    break\n",
    "\n",
    "\n",
    "        self.list = interleaved_list\n",
    "\n",
    "    def probabilistic(self):\n",
    "        # Get lists l1 and l2 and interleaved list l\n",
    "        l1 = copy.copy(self.pair.rankings[0].ranking)\n",
    "        l2 = copy.copy(self.pair.rankings[1].ranking)\n",
    "        lists = [l1, l2]\n",
    "        interleaved_list = []\n",
    "\n",
    "        # As long as some thing is still true: TODO: This may be wrong\n",
    "        while len(l1) > 0 and len(l2) > 0:\n",
    "\n",
    "            # Randomly select one of the lists\n",
    "            ranker = random.choice([0,1])\n",
    "            random_l = lists[ranker]\n",
    "\n",
    "            # Sample d from lx using a softmax\n",
    "            document_rank = self.sample_softmax(len(random_l))\n",
    "            document = random_l[document_rank]\n",
    "\n",
    "            # Put d in l and remove from l1 and l2\n",
    "            interleaved_list.append((document[\"relevance\"], ranker))\n",
    "            for l in lists:\n",
    "                try:\n",
    "                    l.remove(document)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "        self.list = interleaved_list\n",
    "\n",
    "    def sample_softmax(self, length):\n",
    "        \"\"\"\n",
    "        Returns an integer from 0 to length according to a softmax\n",
    "        function.\n",
    "        \"\"\"\n",
    "        normalization = sum([1/i**3 for i in range(1, length + 1)])\n",
    "\n",
    "        sample = random.random()\n",
    "        total = 0\n",
    "\n",
    "        for i in range(1, length + 1):\n",
    "            total += (1/i**3)/normalization\n",
    "            if sample < total:\n",
    "                return i - 1\n",
    "\n",
    "        # You should never get here error\n",
    "        raise notImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4:  Simulate user clicks\n",
    "Having interleaved all the ranking pairs in each group (for each measure) an online experiment could be ran. However, given that we do not have any real users (and the entire homework is a big simulation) we will simulate user clicks.\n",
    "\n",
    "Consider a click model, namely the Position Based Model (PBM). The parameters of PBM can be estimated based on the Expectation-Maximization (EM) method. Implement PBM so that (a) there is a method that learns the parameters of the model given a set of training data, (b) there is a method that predicts the click probability given a ranked list of relevance labels, (c) there is a method that decides - stochastically - whether a document is clicked based on these probabilities.\n",
    "\n",
    "Having implemented the PBM click models, estimate its parameters the Yandex Click Log [file]. \n",
    "\n",
    "After training PBM, use the learnt parameters γr , while instead of the 𝑎uq learnt usefor the non-relevant documents (for a small value of ) and 1- for the relevant documents.\n",
    "\n",
    "Further consider and implement a Random Click Model, which will be used for sanity check.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"data/YandexRelPredChallenge.txt\"\n",
    "\n",
    "def learn_model_parameters(data):\n",
    "\n",
    "    '''This method takes as input the Yandex click log. It first cleans the file\n",
    "    and then trains the alpha and gamma parameters for the PBM model on the basis\n",
    "    of this file. It saves the alphas and gammas (so they only have to be trained\n",
    "    once) to a csv and returns them.'''\n",
    "\n",
    "    # Cleaning data\n",
    "\n",
    "    completed_queries = []\n",
    "\n",
    "    with open(data) as f:\n",
    "        reader = csv.reader(f, delimiter=\"\\t\")\n",
    "        for row in reader:\n",
    "\n",
    "            if row[2] == 'Q':\n",
    "                try:\n",
    "                    completed_queries.append(query)\n",
    "                except:\n",
    "                    pass\n",
    "                query = row\n",
    "                query.append([])\n",
    "                query.append([])\n",
    "\n",
    "                for i in range(5, 8):\n",
    "                    query[15].append(query[i])\n",
    "                    query[16].append(False)\n",
    "\n",
    "            else:\n",
    "                for i in range(0, 3):\n",
    "                    if row[3] == query[15][i]:\n",
    "                        query[16][i] = True\n",
    "\n",
    "    headers = ['SessionID', 'TimePassed', 'TypeOfAction', 'QueryID', 'RegionID', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 'ResultIDs', 'Clicked']\n",
    "    qd_pairs = pd.DataFrame(completed_queries, columns=headers)\n",
    "    qd_pairs = qd_pairs[['QueryID', 'ResultIDs', 'Clicked']]\n",
    "    \n",
    "    ## EM algorithm for finding optimal alpha and gamma ##\n",
    "\n",
    "    # Set parameters to initial values\n",
    "    max_rank = 3\n",
    "\n",
    "    # alpha (attractiveness) is defined per unique query-document pair\n",
    "    alphas = defaultdict(lambda: 0.5)\n",
    "\n",
    "    # gamma (examination) is defined per rank\n",
    "    gammas = [0.5] * max_rank\n",
    "\n",
    "    for ctr in range(0, 50):\n",
    "        print(\"Round \" + str(ctr))\n",
    "\n",
    "        print(\"Update alphas\")\n",
    "\n",
    "        # update one alpha for each QD pair\n",
    "        new_alphas = defaultdict(lambda:1)\n",
    "        qd_count = defaultdict(lambda:2)\n",
    "\n",
    "        for i, session in qd_pairs.iterrows():\n",
    "\n",
    "            if i%10000 == 0:\n",
    "                print(str(i) + \" sessions visited\")\n",
    "\n",
    "            for rank in range(max_rank):\n",
    "                query = session[\"QueryID\"]\n",
    "                result = session[\"ResultIDs\"][rank]\n",
    "                click_u = float(session[\"Clicked\"][rank])\n",
    "\n",
    "                old_alpha = max(alphas[(query, result)], 0.000001)\n",
    "                old_gamma = max(gammas[rank], 0.000001)\n",
    "\n",
    "                qd_count[(query, result)] += 1\n",
    "\n",
    "                # The Formula\n",
    "                new_alphas[(query, result)] += click_u + (1-click_u) * ((1-old_gamma)*old_alpha / (1-old_gamma*old_alpha))\n",
    "\n",
    "\n",
    "        for key, value in qd_count.items():\n",
    "            new_alphas[key] /= value\n",
    "\n",
    "        alphas = new_alphas\n",
    "\n",
    "        print(\"Update gammas\")\n",
    "\n",
    "        new_gammas = [0] * max_rank\n",
    "\n",
    "        # update one gamma per rank\n",
    "        for i, session in qd_pairs.iterrows():\n",
    "\n",
    "            if i%10000 == 0:\n",
    "                print(str(i) + \" sessions visited\")\n",
    "\n",
    "            for rank in range(max_rank):\n",
    "                query = session[\"QueryID\"]\n",
    "                result = session[\"ResultIDs\"][rank]\n",
    "                click_u = float(session[\"Clicked\"][rank])\n",
    "                old_gamma = gammas[rank]\n",
    "                old_alpha = alphas[(query, result)]\n",
    "\n",
    "                new_gammas[rank] += click_u + (1-click_u) * \\\n",
    "                    (old_gamma*(1-old_alpha)) / (1-old_gamma*old_alpha)\n",
    "\n",
    "        for rank, value in enumerate(gammas):\n",
    "            gammas[rank] = new_gammas[rank] / qd_pairs.shape[0]\n",
    "\n",
    "        print(gammas)\n",
    "\n",
    "    alphas_df = pd.DataFrame.from_dict(alphas, orient='index')\n",
    "    alphas_df.to_csv('data/trained_alphas.csv')\n",
    "\n",
    "    gammas_df = pd.DataFrame({'gammas': gammas})\n",
    "    gammas_df.to_csv('data/trained_gammas.csv')\n",
    "\n",
    "    return alphas, gammas\n",
    "\n",
    "alphas, gammas = learn_model_parameters(data)\n",
    "\n",
    "def get_gammas_from_file():\n",
    "    '''Use this method to load gammas when parameters are already trained.'''\n",
    "\n",
    "    try:\n",
    "        gammas = pd.read_csv('data/trained_gammas.csv')\n",
    "        gammas = gammas['gammas'].tolist()\n",
    "\n",
    "        return gammas\n",
    "\n",
    "    except:\n",
    "        print(\"File not found!\")\n",
    "\n",
    "def predict_click_probability(interleaving, gammas):\n",
    "\n",
    "    '''This method takes as input a ranked list (Interleaved.list) and a list\n",
    "    of gamma parameters that determine the examination probability per rank.\n",
    "    The method calculates its own alpha parameters. It returns the click\n",
    "    probabilities of the ranked list (also as a list).'''\n",
    "    \n",
    "    interleaved_list = interleaving.list\n",
    "\n",
    "    # set epsilon to small value (prob that a not-relevant document is clicked)\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    click_probabilities = []\n",
    "\n",
    "    for rank, item in enumerate(interleaving.list):\n",
    "\n",
    "        relevance = item[0]\n",
    "\n",
    "        # check relevance label to determine alphas\n",
    "        if relevance == 1:\n",
    "            alpha = 1-epsilon\n",
    "        else:\n",
    "            alpha = epsilon\n",
    "\n",
    "        # determine gamma\n",
    "        gamma = gammas[rank]\n",
    "\n",
    "        click_prob = alpha * gamma\n",
    "        click_probabilities.append(click_prob)\n",
    "\n",
    "    return click_probabilities\n",
    "\n",
    "def click_documents(interleaved, click_probabilities):\n",
    "\n",
    "    '''This method takes as input a ranked list of documents (Interleaved.list)\n",
    "    and the click probabilities for each rank. It returns a list of the same\n",
    "    length with Booleans indicating whether a document was clicked or not.'''\n",
    "\n",
    "    clicked = []\n",
    "\n",
    "    for rank, item in enumerate(interleaved.list):\n",
    "\n",
    "        rand = random.uniform(0, 1)\n",
    "\n",
    "        if rand < click_probabilities[rank]:\n",
    "            click = True\n",
    "        else:\n",
    "            click = False\n",
    "\n",
    "        clicked.append(click)\n",
    "\n",
    "    return clicked\n",
    "\n",
    "def random_click_model(qd_pairs):\n",
    "\n",
    "    '''This method takes the dataset with all sessions and returns the click\n",
    "    probabilities trained using the random click model. Probabilities are returned\n",
    "    in a length of maximum rank for convenience.'''\n",
    "    max_rank = 3\n",
    "    clicks = 0\n",
    "    docs = 0\n",
    "\n",
    "    for i, session in qd_pairs.iterrows():\n",
    "        for rank in range(max_rank):\n",
    "            docs += 1\n",
    "            if session[\"Clicked\"][rank]:\n",
    "                clicks += 1\n",
    "\n",
    "    click_prob = clicks / docs\n",
    "\n",
    "    click_probs = [click_prob] * max_rank\n",
    "\n",
    "    print(click_probs)\n",
    "\n",
    "    return click_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Simulate interleaving experiment\n",
    "Having implemented the click model, it is time to run the simulated experiment.\n",
    "\n",
    "For each of interleaving experiment run k simulations for each one of the two click models implemented and measure the proportion p of wins for E. Group these proportions in the respective group the interleaved ranking came from. The larger the k the better, but also the larger the k the longer it takes to run the experiment; so make a reasonable choice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_experiment():\n",
    "    \n",
    "    for k.... do step 3 and 4\n",
    "    \n",
    "    return proportion_of_E_wins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Compute sample size\n",
    "Use each one of the afore-computed proportions to compute the sample size needed to detect such a proportion in a statistically significant manner. Allow a chance of falsely rejecting the null hypothesis (i.e. concluding that E is better than P, when it is not) of 5% and a chance of falsely not rejecting the null hypothesis (i.e. not concluding that E is better than P, when it is) of 10%. Use the values above for a power analysis of the proportion test, for the 1-sided case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_sample_size(results_of_one_experiment):\n",
    "    \n",
    "    all_sample_sizes.append(sample_size)\n",
    "    \n",
    "\n",
    "def sample_size_interval(all_sample_sizes):\n",
    "    \n",
    "    return minimum, median, maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Analysis\n",
    "\n",
    "* Report the aforementioned tables for the Random Click Model and PBM and for the two interleaving methods [5pts];\n",
    "* Analyze the results and report your conclusions by observing the results of the experiment [10pts];\n",
    "* Based on the literature, suggest possible improvements to the experimental design and how would you implement them [5pts].\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
